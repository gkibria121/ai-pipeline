{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéôÔ∏è Deepfake Audio Detection Pipeline\n",
    "\n",
    "A deep learning pipeline for detecting AI-generated/synthetic audio using multiple model architectures.\n",
    "\n",
    "## üìã Overview\n",
    "\n",
    "| Feature      | Description                                      |\n",
    "| ------------ | ------------------------------------------------ |\n",
    "| **Datasets** | ASVspoof2019, Fake-or-Real, SceneFake            |\n",
    "| **Task**     | Binary classification (Real vs Fake audio)       |\n",
    "| **Features** | Raw waveform, Mel-spectrogram, LFCC, MFCC, CQT   |\n",
    "| **Models**   | EfficientNet-B2, SEResNet, LCNN, RawNet3, AASIST |\n",
    "| **Metrics**  | EER (Equal Error Rate), Accuracy, t-DCF          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 1: Setup Environment\n",
    "\n",
    "Clone the repository and navigate to the project directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bYARY7a6H3F",
    "outputId": "fb9d2d44-4ed4-4896-a9d5-2098f4df354b"
   },
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!git clone --branch add_fake_or_real_dataset https://github.com/gkibria121/ai-pipeline.git\n",
    "%cd ai-pipeline\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 2: Install Dependencies\n",
    "\n",
    "Install all required Python packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlHSCI6gdSWG",
    "outputId": "90eb7b94-115e-4ef2-c47a-38121681a3a8"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9Di0sKyb6p1"
   },
   "source": [
    "## üìñ Available Options\n",
    "\n",
    "### Models (`--config`)\n",
    "\n",
    "| Config File                            | Model                       | Parameters | Input Type   |\n",
    "| -------------------------------------- | --------------------------- | ---------- | ------------ |\n",
    "| `config/LCNN.conf`                     | LCNN                        | ~0.5M      | Spectrogram  |\n",
    "| `config/LCNN_Large.conf`               | LCNN Large                  | ~1M        | Spectrogram  |\n",
    "| `config/SEResNet.conf`                 | SEResNet                    | ~12M       | Spectrogram  |\n",
    "| `config/EfficientNetB2.conf`           | EfficientNet-B2             | ~9M        | Spectrogram  |\n",
    "| `config/EfficientNetB2_Attention.conf` | EfficientNet-B2 + Attention | ~9M        | Spectrogram  |\n",
    "| `config/RawNet3.conf`                  | RawNet3                     | ~2M        | Raw waveform |\n",
    "| `config/AASIST.conf`                   | AASIST                      | ~0.3M      | Raw waveform |\n",
    "| `config/AASIST-L.conf`                 | AASIST-L                    | ~0.6M      | Raw waveform |\n",
    "\n",
    "### Datasets (`--dataset`)\n",
    "\n",
    "| Flag | Dataset      | Description                                     |\n",
    "| ---- | ------------ | ----------------------------------------------- |\n",
    "| `1`  | ASVspoof2019 | Standard benchmark for audio spoofing detection |\n",
    "| `2`  | Fake-or-Real | Binary classification for fake vs real audio    |\n",
    "| `3`  | SceneFake    | Scene-aware fake audio detection                |\n",
    "\n",
    "### Feature Types (`--feature_type`)\n",
    "\n",
    "| Flag | Feature         | Description                                      |\n",
    "| ---- | --------------- | ------------------------------------------------ |\n",
    "| `0`  | Raw waveform    | Direct waveform processing (for RawNet3, AASIST) |\n",
    "| `1`  | Mel-spectrogram | 128 mel bins                                     |\n",
    "| `2`  | LFCC            | Linear Frequency Cepstral Coefficients           |\n",
    "| `3`  | MFCC            | Mel-Frequency Cepstral Coefficients              |\n",
    "| `4`  | CQT             | Constant-Q Transform                             |\n",
    "\n",
    "### Command Line Arguments\n",
    "\n",
    "```bash\n",
    "python main.py \\\n",
    "    --config <config_file>      # Model configuration file\n",
    "    --dataset <1|2|3>           # Dataset to use\n",
    "    --feature_type <0-4>        # Audio feature representation\n",
    "    --epochs <num>              # Number of training epochs\n",
    "    --batch_size <num>          # Batch size (overrides config)\n",
    "    --random_noise              # Enable data augmentation\n",
    "    --weight_avg                # Enable Stochastic Weight Averaging (SWA)\n",
    "    --eval_best                 # Evaluate on test set when best model is found\n",
    "    --eval                      # Evaluation mode only\n",
    "    --eval_model_weights <path> # Path to model weights for evaluation\n",
    "    --data_subset <0.0-1.0>     # Use subset of data (for quick testing)\n",
    "```\n",
    "\n",
    "### Training Flags\n",
    "\n",
    "| Flag             | Description                                                  |\n",
    "| ---------------- | ------------------------------------------------------------ |\n",
    "| `--random_noise` | Enable data augmentation (RIR, MUSAN, pitch shift, etc.)     |\n",
    "| `--weight_avg`   | Enable Stochastic Weight Averaging for better generalization |\n",
    "| `--eval_best`    | Evaluate on test set each time a new best model is found     |\n",
    "\n",
    "### Augmentation Types (`--random_noise`)\n",
    "\n",
    "When enabled, applies these augmentations randomly:\n",
    "\n",
    "| Augmentation      | Description                                      |\n",
    "| ----------------- | ------------------------------------------------ |\n",
    "| RIR Simulation    | Room Impulse Response - simulates room acoustics |\n",
    "| MUSAN-style Noise | Babble, music, and ambient noise                 |\n",
    "| Gaussian Noise    | Additive white Gaussian noise (SNR: 10-25 dB)    |\n",
    "| Reverberation     | Echo/reverb effects                              |\n",
    "| Pitch Shift       | ¬±4 semitones                                     |\n",
    "| Time Stretch      | 0.85x - 1.15x speed                              |\n",
    "| Gain              | ¬±6 dB volume adjustment                          |\n",
    "| Filters           | Low-pass and high-pass filtering                 |\n",
    "| SpecAugment       | Frequency and time masking for spectrograms      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 3: Download Fake-or-Real Dataset\n",
    "\n",
    "Download the Fake-or-Real dataset (2-second audio clips). This contains:\n",
    "\n",
    "- **Training**: 13,956 samples (6,978 real + 6,978 fake)\n",
    "- **Validation**: 2,826 samples (1,413 real + 1,413 fake)\n",
    "- **Testing**: 1,088 samples (544 real + 544 fake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python download_dataset.py --dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ Step 4: Train Models\n",
    "\n",
    "### LCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --config config/LCNN.conf --feature_type 1 --dataset 2 --epochs 20 --random_noise --weight_avg --eval_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCNN Large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --config config/LCNN_Large.conf --feature_type 1 --dataset 2 --epochs 20 --random_noise --weight_avg --eval_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEResNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --config config/SEResNet.conf --feature_type 1 --dataset 2 --epochs 15 --random_noise --weight_avg --eval_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet-B2 with Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --config config/EfficientNetB2_Attention.conf --feature_type 1 --dataset 2 --epochs 20 --random_noise --weight_avg --eval_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RawNet3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --config config/RawNet3.conf --feature_type 0 --dataset 2 --epochs 15 --random_noise --weight_avg --eval_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AASIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --config config/AASIST.conf --feature_type 0 --dataset 2 --epochs 30 --random_noise --weight_avg --eval_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Output Structure\n",
    "\n",
    "After training, results are saved in `exp_result/`:\n",
    "\n",
    "```\n",
    "exp_result/\n",
    "‚îî‚îÄ‚îÄ <dataset>_<track>_<model>_<flags>_ep<epochs>_bs<batch>_feat<feature>/\n",
    "    ‚îú‚îÄ‚îÄ config.conf              # Copy of training config\n",
    "    ‚îú‚îÄ‚îÄ weights/                 # Model checkpoints\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ best.pth            # Best model (lowest dev EER)\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ swa.pth             # SWA averaged model\n",
    "    ‚îú‚îÄ‚îÄ metrics/                 # Training metrics\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ epoch_metrics.json  # Per-epoch metrics\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ final_summary.json  # Final results\n",
    "    ‚îú‚îÄ‚îÄ metric_log.txt          # Training log\n",
    "    ‚îú‚îÄ‚îÄ evaluation_results.txt  # Final evaluation\n",
    "    ‚îî‚îÄ‚îÄ events.out.*            # TensorBoard logs\n",
    "```\n",
    "\n",
    "### Metrics\n",
    "\n",
    "| Metric       | Description                                    |\n",
    "| ------------ | ---------------------------------------------- |\n",
    "| **EER**      | Equal Error Rate                               |\n",
    "| **Accuracy** | Classification accuracy                        |\n",
    "| **t-DCF**    | Tandem Detection Cost Function (ASVspoof only) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç Step 5: Evaluate Model\n",
    "\n",
    "Evaluate a trained model on the test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace path with your trained model\n",
    "#!python main.py --config config/LCNN.conf --dataset 2 --feature_type 1 --eval --eval_model_weights ./exp_result/<your_model_folder>/weights/best.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üí° Common Issues\n",
    "\n",
    "| Issue           | Solution                                                          |\n",
    "| --------------- | ----------------------------------------------------------------- |\n",
    "| Out of memory   | Reduce `--batch_size 16` or `--batch_size 8`                      |\n",
    "| Slow training   | Mixed precision is enabled by default (`use_amp: true` in config) |\n",
    "| Need quick test | Use `--data_subset 0.1` to train on 10% of data                   |\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
