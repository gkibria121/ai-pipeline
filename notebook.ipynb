{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéôÔ∏è Deepfake Audio Detection Pipeline\n",
    "\n",
    "A deep learning pipeline for detecting AI-generated/synthetic audio using multiple model architectures.\n",
    "\n",
    "## üìã Overview\n",
    "\n",
    "| Feature      | Description                                      |\n",
    "| ------------ | ------------------------------------------------ |\n",
    "| **Datasets** | ASVspoof2019, Fake-or-Real, SceneFake            |\n",
    "| **Task**     | Binary classification (Real vs Fake audio)       |\n",
    "| **Features** | Raw waveform, Mel-spectrogram, LFCC, MFCC, CQT   |\n",
    "| **Models**   | EfficientNet-B2, SEResNet, LCNN, RawNet3, AASIST |\n",
    "| **Metrics**  | EER (Equal Error Rate), Accuracy, t-DCF          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 1: Setup Environment\n",
    "\n",
    "Clone the repository and navigate to the project directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bYARY7a6H3F",
    "outputId": "fb9d2d44-4ed4-4896-a9d5-2098f4df354b"
   },
   "outputs": [],
   "source": [
    "# %cd /content\n",
    "# !git clone  https://github.com/gkibria121/ai-pipeline.git\n",
    "# %cd ai-pipeline\n",
    "# !git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 2: Install Dependencies\n",
    "\n",
    "Install all required Python packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlHSCI6gdSWG",
    "outputId": "90eb7b94-115e-4ef2-c47a-38121681a3a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.9.1)\n",
      "Requirement already satisfied: torchcontrib in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from -r requirements.txt (line 2)) (0.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from -r requirements.txt (line 3)) (2.3.5)\n",
      "Requirement already satisfied: soundfile in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from -r requirements.txt (line 4)) (0.13.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: librosa in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from -r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: kagglehub in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from -r requirements.txt (line 7)) (0.3.13)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from -r requirements.txt (line 8)) (3.10.7)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from -r requirements.txt (line 9)) (2.20.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from -r requirements.txt (line 10)) (0.13.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from -r requirements.txt (line 11)) (2.3.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (2025.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (80.9.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from soundfile->-r requirements.txt (line 4)) (2.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from tqdm->-r requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from librosa->-r requirements.txt (line 6)) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from librosa->-r requirements.txt (line 6)) (0.63.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from librosa->-r requirements.txt (line 6)) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from librosa->-r requirements.txt (line 6)) (1.8.0)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from librosa->-r requirements.txt (line 6)) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from librosa->-r requirements.txt (line 6)) (5.2.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from librosa->-r requirements.txt (line 6)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from librosa->-r requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from librosa->-r requirements.txt (line 6)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from librosa->-r requirements.txt (line 6)) (1.1.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from kagglehub->-r requirements.txt (line 7)) (25.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from kagglehub->-r requirements.txt (line 7)) (6.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from kagglehub->-r requirements.txt (line 7)) (2.32.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 8)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 8)) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 8)) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 8)) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 8)) (2.9.0.post0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 9)) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 9)) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 9)) (3.10)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 9)) (6.33.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 9)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from tensorboard->-r requirements.txt (line 9)) (3.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from pandas->-r requirements.txt (line 11)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from pandas->-r requirements.txt (line 11)) (2025.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 4)) (2.23)\n",
      "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 6)) (0.46.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 6)) (4.5.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 7)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 7)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 7)) (2.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from requests->kagglehub->-r requirements.txt (line 7)) (2025.11.12)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from scikit-learn>=1.1.0->librosa->-r requirements.txt (line 6)) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\gk\\desktop\\asvspoof2019\\ai-pipeline\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 9)) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9Di0sKyb6p1"
   },
   "source": [
    "## üìñ Available Options\n",
    "\n",
    "### Models (`--config`)\n",
    "\n",
    "| Config File                            | Model                       | Parameters | Input Type   |\n",
    "| -------------------------------------- | --------------------------- | ---------- | ------------ |\n",
    "| `config/LCNN.conf`                     | LCNN                        | ~0.5M      | Spectrogram  |\n",
    "| `config/LCNN_Large.conf`               | LCNN Large                  | ~1M        | Spectrogram  |\n",
    "| `config/SEResNet.conf`                 | SEResNet                    | ~12M       | Spectrogram  |\n",
    "| `config/EfficientNetB2.conf`           | EfficientNet-B2             | ~9M        | Spectrogram  |\n",
    "| `config/EfficientNetB2_Attention.conf` | EfficientNet-B2 + Attention | ~9M        | Spectrogram  |\n",
    "| `config/RawNet3.conf`                  | RawNet3                     | ~2M        | Raw waveform |\n",
    "| `config/AASIST.conf`                   | AASIST                      | ~0.3M      | Raw waveform |\n",
    "| `config/AASIST-L.conf`                 | AASIST-L                    | ~0.6M      | Raw waveform |\n",
    "\n",
    "### Datasets (`--dataset`)\n",
    "\n",
    "| Flag | Dataset      | Description                                     |\n",
    "| ---- | ------------ | ----------------------------------------------- |\n",
    "| `1`  | ASVspoof2019 | Standard benchmark for audio spoofing detection |\n",
    "| `2`  | Fake-or-Real | Binary classification for fake vs real audio    |\n",
    "| `3`  | SceneFake    | Scene-aware fake audio detection                |\n",
    "\n",
    "### Feature Types (`--feature_type`)\n",
    "\n",
    "| Flag | Feature         | Description                                      |\n",
    "| ---- | --------------- | ------------------------------------------------ |\n",
    "| `0`  | Raw waveform    | Direct waveform processing (for RawNet3, AASIST) |\n",
    "| `1`  | Mel-spectrogram | 128 mel bins                                     |\n",
    "| `2`  | LFCC            | Linear Frequency Cepstral Coefficients           |\n",
    "| `3`  | MFCC            | Mel-Frequency Cepstral Coefficients              |\n",
    "| `4`  | CQT             | Constant-Q Transform                             |\n",
    "\n",
    "### Command Line Arguments\n",
    "\n",
    "```bash\n",
    "python main.py \\\n",
    "    --config <config_file>      # Model configuration file\n",
    "    --dataset <1|2|3>           # Dataset to use\n",
    "    --feature_type <0-4>        # Audio feature representation\n",
    "    --epochs <num>              # Number of training epochs\n",
    "    --batch_size <num>          # Batch size (overrides config)\n",
    "    --random_noise              # Enable data augmentation\n",
    "    --weight_avg                # Enable Stochastic Weight Averaging (SWA)\n",
    "    --eval_best                 # Evaluate on test set when best model is found\n",
    "    --eval                      # Evaluation mode only\n",
    "    --eval_model_weights <path> # Path to model weights for evaluation\n",
    "    --data_subset <0.0-1.0>     # Use subset of data (for quick testing)\n",
    "```\n",
    "\n",
    "### Training Flags\n",
    "\n",
    "| Flag             | Description                                                  |\n",
    "| ---------------- | ------------------------------------------------------------ |\n",
    "| `--random_noise` | Enable data augmentation (RIR, MUSAN, pitch shift, etc.)     |\n",
    "| `--weight_avg`   | Enable Stochastic Weight Averaging for better generalization |\n",
    "| `--eval_best`    | Evaluate on test set each time a new best model is found     |\n",
    "\n",
    "### Augmentation Types (`--random_noise`)\n",
    "\n",
    "When enabled, applies these augmentations randomly:\n",
    "\n",
    "| Augmentation      | Description                                      |\n",
    "| ----------------- | ------------------------------------------------ |\n",
    "| RIR Simulation    | Room Impulse Response - simulates room acoustics |\n",
    "| MUSAN-style Noise | Babble, music, and ambient noise                 |\n",
    "| Gaussian Noise    | Additive white Gaussian noise (SNR: 10-25 dB)    |\n",
    "| Reverberation     | Echo/reverb effects                              |\n",
    "| Pitch Shift       | ¬±4 semitones                                     |\n",
    "| Time Stretch      | 0.85x - 1.15x speed                              |\n",
    "| Gain              | ¬±6 dB volume adjustment                          |\n",
    "| Filters           | Low-pass and high-pass filtering                 |\n",
    "| SpecAugment       | Frequency and time masking for spectrograms      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Step 3: Download Fake-or-Real Dataset\n",
    "\n",
    "Download the Fake-or-Real dataset (2-second audio clips). This contains:\n",
    "\n",
    "- **Training**: 13,956 samples (6,978 real + 6,978 fake)\n",
    "- **Validation**: 2,826 samples (1,413 real + 1,413 fake)\n",
    "- **Testing**: 1,088 samples (544 real + 544 fake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python download_dataset.py --dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Processing:   1%|          | 1/100 [00:00<00:10,  9.59it/s]\n",
      "Processing:   2%|‚ñè         | 2/100 [00:00<00:10,  9.78it/s]\n",
      "Processing:   3%|‚ñé         | 3/100 [00:00<00:09,  9.85it/s]\n",
      "Processing:   4%|‚ñç         | 4/100 [00:00<00:09,  9.88it/s]\n",
      "Processing:   5%|‚ñå         | 5/100 [00:00<00:09,  9.91it/s]\n",
      "Processing:   6%|‚ñå         | 6/100 [00:00<00:09,  9.92it/s]\n",
      "Processing:   7%|‚ñã         | 7/100 [00:00<00:09,  9.92it/s]\n",
      "Processing:   8%|‚ñä         | 8/100 [00:00<00:09,  9.93it/s]\n",
      "Processing:   9%|‚ñâ         | 9/100 [00:00<00:09,  9.93it/s]\n",
      "Processing:  10%|‚ñà         | 10/100 [00:01<00:09,  9.94it/s]\n",
      "Processing:  11%|‚ñà         | 11/100 [00:01<00:08,  9.93it/s]\n",
      "Processing:  12%|‚ñà‚ñè        | 12/100 [00:01<00:08,  9.93it/s]\n",
      "Processing:  13%|‚ñà‚ñé        | 13/100 [00:01<00:08,  9.94it/s]\n",
      "Processing:  14%|‚ñà‚ñç        | 14/100 [00:01<00:08,  9.95it/s]\n",
      "Processing:  15%|‚ñà‚ñå        | 15/100 [00:01<00:08,  9.96it/s]\n",
      "Processing:  16%|‚ñà‚ñå        | 16/100 [00:01<00:08,  9.95it/s]\n",
      "Processing:  17%|‚ñà‚ñã        | 17/100 [00:01<00:08,  9.95it/s]\n",
      "Processing:  18%|‚ñà‚ñä        | 18/100 [00:01<00:08,  9.96it/s]\n",
      "Processing:  19%|‚ñà‚ñâ        | 19/100 [00:01<00:08,  9.96it/s]\n",
      "Processing:  20%|‚ñà‚ñà        | 20/100 [00:02<00:08,  9.95it/s]\n",
      "Processing:  21%|‚ñà‚ñà        | 21/100 [00:02<00:07,  9.95it/s]\n",
      "Processing:  22%|‚ñà‚ñà‚ñè       | 22/100 [00:02<00:07,  9.94it/s]\n",
      "Processing:  23%|‚ñà‚ñà‚ñé       | 23/100 [00:02<00:07,  9.94it/s]\n",
      "Processing:  24%|‚ñà‚ñà‚ñç       | 24/100 [00:02<00:07,  9.94it/s]\n",
      "Processing:  25%|‚ñà‚ñà‚ñå       | 25/100 [00:02<00:07,  9.95it/s]\n",
      "Processing:  26%|‚ñà‚ñà‚ñå       | 26/100 [00:02<00:07,  9.95it/s]\n",
      "Processing:  27%|‚ñà‚ñà‚ñã       | 27/100 [00:02<00:07,  9.95it/s]\n",
      "Processing:  28%|‚ñà‚ñà‚ñä       | 28/100 [00:02<00:07,  9.94it/s]\n",
      "Processing:  29%|‚ñà‚ñà‚ñâ       | 29/100 [00:02<00:07,  9.95it/s]\n",
      "Processing:  30%|‚ñà‚ñà‚ñà       | 30/100 [00:03<00:07,  9.95it/s]\n",
      "Processing:  31%|‚ñà‚ñà‚ñà       | 31/100 [00:03<00:06,  9.94it/s]\n",
      "Processing:  32%|‚ñà‚ñà‚ñà‚ñè      | 32/100 [00:03<00:06,  9.94it/s]\n",
      "Processing:  33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [00:03<00:06,  9.94it/s]\n",
      "Processing:  34%|‚ñà‚ñà‚ñà‚ñç      | 34/100 [00:03<00:06,  9.95it/s]\n",
      "Processing:  35%|‚ñà‚ñà‚ñà‚ñå      | 35/100 [00:03<00:06,  9.95it/s]\n",
      "Processing:  36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [00:03<00:06,  9.95it/s]\n",
      "Processing:  37%|‚ñà‚ñà‚ñà‚ñã      | 37/100 [00:03<00:06,  9.95it/s]\n",
      "Processing:  38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [00:03<00:06,  9.95it/s]\n",
      "Processing:  39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [00:03<00:06,  9.95it/s]\n",
      "Processing:  40%|‚ñà‚ñà‚ñà‚ñà      | 40/100 [00:04<00:06,  9.96it/s]\n",
      "Processing:  41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [00:04<00:05,  9.95it/s]\n",
      "Processing:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [00:04<00:05,  9.96it/s]\n",
      "Processing:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 43/100 [00:04<00:05,  9.96it/s]\n",
      "Processing:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [00:04<00:05,  9.95it/s]\n",
      "Processing:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/100 [00:04<00:05,  9.96it/s]\n",
      "Processing:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [00:04<00:05,  9.95it/s]\n",
      "Processing:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [00:04<00:05,  9.95it/s]\n",
      "Processing:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [00:04<00:05,  9.95it/s]\n",
      "Processing:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 49/100 [00:04<00:05,  9.94it/s]\n",
      "Processing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [00:05<00:05,  9.95it/s]\n",
      "Processing:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 51/100 [00:05<00:04,  9.95it/s]\n",
      "Processing:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [00:05<00:04,  9.94it/s]\n",
      "Processing:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 53/100 [00:05<00:04,  9.94it/s]\n",
      "Processing:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 54/100 [00:05<00:04,  9.94it/s]\n",
      "Processing:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/100 [00:05<00:04,  9.94it/s]\n",
      "Processing:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 56/100 [00:05<00:04,  9.94it/s]\n",
      "Processing:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [00:05<00:04,  9.93it/s]\n",
      "Processing:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 58/100 [00:05<00:04,  9.94it/s]\n",
      "Processing:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [00:05<00:04,  9.95it/s]\n",
      "Processing:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [00:06<00:04,  9.95it/s]\n",
      "Processing:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [00:06<00:03,  9.95it/s]\n",
      "Processing:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/100 [00:06<00:03,  9.94it/s]\n",
      "Processing:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [00:06<00:03,  9.95it/s]\n",
      "Processing:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 64/100 [00:06<00:03,  9.95it/s]\n",
      "Processing:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 65/100 [00:06<00:03,  9.96it/s]\n",
      "Processing:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [00:06<00:03,  9.95it/s]\n",
      "Processing:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 67/100 [00:06<00:03,  9.95it/s]\n",
      "Processing:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [00:06<00:03,  9.95it/s]\n",
      "Processing:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [00:06<00:03,  9.94it/s]\n",
      "Processing:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [00:07<00:03,  9.95it/s]\n",
      "Processing:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [00:07<00:02,  9.95it/s]\n",
      "Processing:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [00:07<00:02,  9.94it/s]\n",
      "Processing:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [00:07<00:02,  9.95it/s]\n",
      "Processing:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 74/100 [00:07<00:02,  9.95it/s]\n",
      "Processing:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [00:07<00:02,  9.95it/s]\n",
      "Processing:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/100 [00:07<00:02,  9.96it/s]\n",
      "Processing:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [00:07<00:02,  9.96it/s]\n",
      "Processing:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 78/100 [00:07<00:02,  9.96it/s]\n",
      "Processing:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [00:07<00:02,  9.97it/s]\n",
      "Processing:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [00:08<00:02,  9.96it/s]\n",
      "Processing:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 81/100 [00:08<00:01,  9.96it/s]\n",
      "Processing:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 82/100 [00:08<00:01,  9.95it/s]\n",
      "Processing:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 83/100 [00:08<00:01,  9.94it/s]\n",
      "Processing:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [00:08<00:01,  9.95it/s]\n",
      "Processing:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [00:08<00:01,  9.95it/s]\n",
      "Processing:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/100 [00:08<00:01,  9.94it/s]\n",
      "Processing:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [00:08<00:01,  9.94it/s]\n",
      "Processing:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 88/100 [00:08<00:01,  9.93it/s]\n",
      "Processing:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [00:08<00:01,  9.93it/s]\n",
      "Processing:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [00:09<00:01,  9.94it/s]\n",
      "Processing:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [00:09<00:00,  9.94it/s]\n",
      "Processing:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 92/100 [00:09<00:00,  9.93it/s]\n",
      "Processing:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [00:09<00:00,  9.93it/s]\n",
      "Processing:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94/100 [00:09<00:00,  9.94it/s]\n",
      "Processing:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [00:09<00:00,  9.95it/s]\n",
      "Processing:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/100 [00:09<00:00,  9.94it/s]\n",
      "Processing:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [00:09<00:00,  9.94it/s]\n",
      "Processing:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 98/100 [00:09<00:00,  9.94it/s]\n",
      "Processing:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [00:09<00:00,  9.94it/s]\n",
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:10<00:00,  9.95it/s]\n",
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:10<00:00,  9.94it/s]\n"
     ]
    }
   ],
   "source": [
    "!python realtime.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ Step 4: Train Models\n",
    "\n",
    "### LCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python -u main.py --config config/LCNN.conf --feature_type 1 --dataset 2 --epochs 20 --random_noise --weight_avg --eval_best --cpu --data_subset 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCNN Large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gk\\Desktop\\asvspoof2019\\ai-pipeline\\feature_analysis.py:234: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gk\\Desktop\\asvspoof2019\\ai-pipeline\\main.py\", line 1114, in <module>\n",
      "    main(parser.parse_args())\n",
      "  File \"c:\\Users\\gk\\Desktop\\asvspoof2019\\ai-pipeline\\main.py\", line 325, in main\n",
      "    raise ValueError(\"GPU not detected! Use --cpu flag to run on CPU (slower).\")\n",
      "ValueError: GPU not detected! Use --cpu flag to run on CPU (slower).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATASET: Fake-or-Real (Type 2)\n",
      "======================================================================\n",
      "‚úÖ Eval on best: ENABLED (will evaluate on test set when best model found)\n",
      "‚úÖ Random augmentation: ENABLED (RIR, MUSAN-style noise, pitch shift, time stretch, SpecAugment)\n",
      "‚úÖ Weight averaging (SWA): ENABLED\n",
      "\n",
      "==================================================\n",
      "Feature Type: 1 (MEL_SPECTROGRAM)\n",
      "Generating feature analysis visualization...\n",
      "==================================================\n",
      "Using sample: file10005.mp3.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav\n",
      "‚úì Feature analysis saved to: exp_result\\FakeorReal_audio_LCNN_Large_rand_ep20_bs24_feat1\\feature_analysis\\feature_analysis_mel_spectrogram.png\n"
     ]
    }
   ],
   "source": [
    "!python -u main.py --config config/LCNN_Large.conf --feature_type 1 --dataset 2 --epochs 20 --random_noise --weight_avg --eval_best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEResNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u main.py --config config/SEResNet.conf --feature_type 1 --dataset 2 --epochs 15 --random_noise --weight_avg --eval_best  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet-B2 with Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u main.py --config config/EfficientNetB2_Attention.conf --feature_type 1 --dataset 2 --epochs 20 --random_noise --weight_avg --eval_best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RawNet3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u main.py --config config/RawNet3.conf --feature_type 0 --dataset 2 --epochs 15 --random_noise --weight_avg --eval_best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AASIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u main.py --config config/AASIST.conf --feature_type 0 --dataset 2 --epochs 30 --random_noise --weight_avg --eval_best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Output Structure\n",
    "\n",
    "After training, results are saved in `exp_result/`:\n",
    "\n",
    "```\n",
    "exp_result/\n",
    "‚îî‚îÄ‚îÄ <dataset>_<track>_<model>_<flags>_ep<epochs>_bs<batch>_feat<feature>/\n",
    "    ‚îú‚îÄ‚îÄ config.conf              # Copy of training config\n",
    "    ‚îú‚îÄ‚îÄ weights/                 # Model checkpoints\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ best.pth            # Best model (lowest dev EER)\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ swa.pth             # SWA averaged model\n",
    "    ‚îú‚îÄ‚îÄ metrics/                 # Training metrics\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ epoch_metrics.json  # Per-epoch metrics\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ final_summary.json  # Final results\n",
    "    ‚îú‚îÄ‚îÄ metric_log.txt          # Training log\n",
    "    ‚îú‚îÄ‚îÄ evaluation_results.txt  # Final evaluation\n",
    "    ‚îî‚îÄ‚îÄ events.out.*            # TensorBoard logs\n",
    "```\n",
    "\n",
    "### Metrics\n",
    "\n",
    "| Metric       | Description                                    |\n",
    "| ------------ | ---------------------------------------------- |\n",
    "| **EER**      | Equal Error Rate                               |\n",
    "| **Accuracy** | Classification accuracy                        |\n",
    "| **t-DCF**    | Tandem Detection Cost Function (ASVspoof only) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç Step 5: Evaluate Model\n",
    "\n",
    "Evaluate a trained model on the test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace path with your trained model\n",
    "#!python main.py --config config/LCNN.conf --dataset 2 --feature_type 1 --eval --eval_model_weights ./exp_result/<your_model_folder>/weights/best.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üí° Common Issues\n",
    "\n",
    "| Issue           | Solution                                                          |\n",
    "| --------------- | ----------------------------------------------------------------- |\n",
    "| Out of memory   | Reduce `--batch_size 16` or `--batch_size 8`                      |\n",
    "| Slow training   | Mixed precision is enabled by default (`use_amp: true` in config) |\n",
    "| Need quick test | Use `--data_subset 0.1` to train on 10% of data                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß™ Step 6: Feature & Model Experiments\n",
    "\n",
    "Run experiments with different feature types and model configurations to find the best combination.\n",
    "\n",
    "### Feature Type Reference\n",
    "\n",
    "| Feature             | Best For            | Models                       |\n",
    "| ------------------- | ------------------- | ---------------------------- |\n",
    "| `0` Raw             | End-to-end learning | RawNet3, AASIST              |\n",
    "| `1` Mel-spectrogram | General purpose     | LCNN, EfficientNet, SEResNet |\n",
    "| `2` LFCC            | Speech features     | LCNN, SEResNet               |\n",
    "| `3` MFCC            | Traditional speech  | All spectrogram models       |\n",
    "| `4` CQT             | Harmonic analysis   | LCNN, EfficientNet           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: LCNN with CQT Features\n",
    "\n",
    "CQT (Constant-Q Transform) provides excellent harmonic resolution for detecting synthesis artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u main.py --config config/LCNN.conf --feature_type 4 --dataset 2 --epochs 20 --random_noise --weight_avg --eval_best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: LCNN with LFCC Features\n",
    "\n",
    "LFCC (Linear Frequency Cepstral Coefficients) is widely used for spoofing detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u main.py --config config/LCNN.conf --feature_type 2 --dataset 2 --epochs 20 --random_noise --weight_avg --eval_best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: EfficientNet-B2 with CQT Features\n",
    "\n",
    "EfficientNet with CQT can capture fine-grained frequency patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u main.py --config config/EfficientNetB2_Attention.conf --feature_type 4 --dataset 2 --epochs 20 --random_noise --weight_avg --eval_best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: SEResNet with MFCC Features\n",
    "\n",
    "SEResNet with MFCC for traditional speech feature analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u main.py --config config/SEResNet.conf --feature_type 3 --dataset 2 --epochs 15 --random_noise --weight_avg --eval_best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5: AASIST-L (Large) with Raw Waveform\n",
    "\n",
    "AASIST-L is a larger version with more capacity for complex patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u main.py --config config/AASIST-L.conf --feature_type 0 --dataset 2 --epochs 30 --random_noise --weight_avg --eval_best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experiment 6: SimpleCNN Baseline with Mel-spectrogram\n",
    "\n",
    "A lightweight baseline model for quick comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u main.py --config config/SimpleCNN.conf --feature_type 1 --dataset 2 --epochs 25 --random_noise --weight_avg --eval_best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 7: LCNN Large with LFCC Features\n",
    "\n",
    "Larger LCNN model with LFCC for better spoofing artifact detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u main.py --config config/LCNN_Large.conf --feature_type 2 --dataset 2 --epochs 20 --random_noise --weight_avg --eval_best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà Step 7: Compare All Results\n",
    "\n",
    "After running experiments, visualize and compare all model results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all trained models\n",
    "!python visualize_results.py --path \"exp_result/*/metrics\" --compare --show-summary --output ./comparison_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Comparison Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "\n",
    "# Display comparison plot if it exists\n",
    "comparison_plot = Path(\"./comparison_plots/model_comparison.png\")\n",
    "if comparison_plot.exists():\n",
    "    display(Image(filename=str(comparison_plot)))\n",
    "else:\n",
    "    print(\"Run the comparison command above first to generate plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Experiment Summary Table\n",
    "\n",
    "After completing all experiments, fill in the results:\n",
    "\n",
    "| Experiment | Model           | Feature      | Epochs | Best EER (%) | Best Accuracy (%) |\n",
    "| ---------- | --------------- | ------------ | ------ | ------------ | ----------------- |\n",
    "| Baseline 1 | LCNN            | Mel-spec (1) | 20     | -            | -                 |\n",
    "| Baseline 2 | EfficientNet-B2 | Mel-spec (1) | 20     | -            | -                 |\n",
    "| Baseline 3 | RawNet3         | Raw (0)      | 15     | -            | -                 |\n",
    "| Baseline 4 | AASIST          | Raw (0)      | 30     | -            | -                 |\n",
    "| Exp 1      | LCNN            | CQT (4)      | 20     | -            | -                 |\n",
    "| Exp 2      | LCNN            | LFCC (2)     | 20     | -            | -                 |\n",
    "| Exp 3      | EfficientNet-B2 | CQT (4)      | 20     | -            | -                 |\n",
    "| Exp 4      | SEResNet        | MFCC (3)     | 15     | -            | -                 |\n",
    "| Exp 5      | AASIST-L        | Raw (0)      | 30     | -            | -                 |\n",
    "| Exp 6      | SimpleCNN       | Mel-spec (1) | 25     | -            | -                 |\n",
    "| Exp 7      | LCNN Large      | LFCC (2)     | 20     | -            | -                 |\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "- Lower EER is better (0% = perfect)\n",
    "- Higher Accuracy is better (100% = perfect)\n",
    "- CQT and LFCC features often work well for spoofing detection\n",
    "- Raw waveform models (RawNet3, AASIST) learn features automatically\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
